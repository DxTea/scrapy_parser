# scrapy_parser
## Technical specification
Используя фреймворк `Scrapy` необходимо написать код программы для получения информации о товарах интернет-магазина из списка категорий по заранее заданному шаблону, 
данную информацию необходимо представлять в виде списка словарей (один товар - один словарь) и сохрянить в файл с расширением `.json`
## Features
* Красивое и удобное логирование:
  * В консоль выводится ссылка на товар по которому собирается информация
  * Прогрессбары
  * В случае возникновения ошибки во время парсинга информация об ошибке и ссылка на страницу сохраняются в файле `error_log.txt`
  * Выводится время выполнения программы
* Настроены прокси сервера, `Scrapy` будет случайным образом выбирать прокси из списка при каждом запросе, что поможет обойти ограничения и блокировки.
* Каждый запрос содержит случайный `User-Agent` и `Referer` из списка `USER_AGENT_LIST`. Это поможет избежать блокировки прокси и сделает парсинг более надежным.
* Использован `ItemLoader`, который позволяет структурировать извлечение данных из страниц и уменьшить дублирование кода.
* Обработка исключений
* Пагинация
## Docker
* Установите `Docker` на свой компьютер: `https://www.docker.com/get-started`
* Склонируйте git-репозиторий с проектом на свой компьютер: `git clone <URL репозитория>`
* Перейдите в корневую папку проекта в командной строке или терминале.
* Соберите образ Docker из Dockerfile, выполнив команду: `docker build -t apteka_spider .`
* После успешной сборки образа запустите контейнер: `docker run apteka_spider`
## How to use
* Скопируйте `URL` репозитория.
* Откройте `командную строку (терминал)` на вашем компьютере.
* Введите команду `git clone <URL репозитория>`
* Перейдите в папку с клонированным репозиторием с помощью `cd <название папки>`
* Убедитесь, что у вас установлен `Python версии 3.11`
* Установите необходимые зависимости `pip install -r requirements.txt`
* Внутри папки с проектом запустите парсер с помощью команды: `python <имя_файла_с_парсером>.py`
* После успешного завершения парсинга, результаты будут сохранены в JSON-файле, который вы найдете в папке `parsed_data`
* В случае возникновения ошибок во время парсинга, информация об ошибках будет залогирована в файл `error_log.txt` в папке с проектом.
* Чтобы изменить категории для парсинга, вам нужно будет изменить список `CATEGORIES` в классе `AptekaSpider`. В этом списке вы можете указать новые категории или удалить существующие, а также изменить URL-адреса категорий.
* Чтобы изменить прокси серверы необходимо внести изменения в `ROTATING_PROXY_LIST` в файле `settings.py`.
